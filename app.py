import streamlit as st
import genanki
import nltk
import requests
from gtts import gTTS
from deep_translator import GoogleTranslator
from nltk.corpus import wordnet as wn
import time, io, os, re
from PIL import Image, ImageDraw

# -----------------------------
# --- NLTK setup cho Streamlit Cloud ---
# -----------------------------
nltk_data_dir = os.path.join(os.getcwd(), "nltk_data")
os.makedirs(nltk_data_dir, exist_ok=True)
nltk.data.path.append(nltk_data_dir)

# --- T·∫£i d·ªØ li·ªáu NLTK n·∫øu ch∆∞a c√≥ ---
for resource in ["averaged_perceptron_tagger", "wordnet", "punkt"]:
    try:
        if resource == "averaged_perceptron_tagger":
            nltk.data.find(f"taggers/{resource}")
        elif resource == "wordnet":
            nltk.data.find(f"corpora/{resource}")
        else:
            nltk.data.find(f"tokenizers/{resource}")
    except LookupError:
        nltk.download(resource, download_dir=nltk_data_dir)

# -----------------------------
# --- H√†m x√°c ƒë·ªãnh lo·∫°i t·ª´ ---
# -----------------------------
def pos_simple(tag):
    if tag.startswith("NN"): return "danh t·ª´"
    if tag.startswith("VB"): return "ƒë·ªông t·ª´"
    if tag.startswith("JJ"): return "t√≠nh t·ª´"
    if tag.startswith("RB"): return "tr·∫°ng t·ª´"
    return "kh√°c"

def get_pos(word):
    try:
        pos = nltk.pos_tag([word])[0][1]
        return pos_simple(pos)
    except:
        return "kh√°c"

# -----------------------------
# --- H√†m l·∫•y nghƒ©a ti·∫øng Anh ---
# -----------------------------
def get_definition(word):
    syns = wn.synsets(word)
    return syns[0].definition() if syns else ""

# -----------------------------
# --- H√†m d·ªãch sang ti·∫øng Vi·ªát ---
# -----------------------------
def translate_word(word):
    try:
        return GoogleTranslator(source="en", target="vi").translate(word)
    except:
        return word

# -----------------------------
# --- H√†m l·∫•y h√¨nh ·∫£nh t·ª´ Wikipedia ---
# -----------------------------
def fetch_image(word):
    url = "https://en.wikipedia.org/w/api.php"
    params = {
        "action": "query",
        "format": "json",
        "prop": "pageimages",
        "generator": "search",
        "gsrsearch": word,
        "gsrlimit": 1,
        "piprop": "thumbnail",
        "pithumbsize": 400,
    }
    try:
        r = requests.get(url, params=params, timeout=10)
        data = r.json().get("query", {}).get("pages", {})
        for p in data.values():
            img = p.get("thumbnail", {}).get("source")
            if img:
                return requests.get(img, timeout=10).content
    except:
        pass

    # fallback: placeholder
    img = Image.new("RGB", (400, 250), (230,230,230))
    d = ImageDraw.Draw(img)
    d.text((20,100), word, fill=(0,0,0))
    buf = io.BytesIO()
    img.save(buf, format="JPEG")
    return buf.getvalue()

# -----------------------------
# --- H√†m t·∫°o t√™n file an to√†n ---
# -----------------------------
def safe_name(w): 
    return re.sub(r"[^a-z0-9]", "_", w.lower())

# -----------------------------
# --- Streamlit UI ---
# -----------------------------
st.title("üá¨üáß Auto Flashcard Generator (Python Web App)")
st.write("D√°n danh s√°ch t·ª´ v·ª±ng (m·ªói d√≤ng 1 t·ª´) ƒë·ªÉ t·∫°o file .apkg (Anki).")

input_text = st.text_area("Nh·∫≠p danh s√°ch t·ª´:", height=200)

if st.button("Generate Flashcards"):
    lines = [w.strip() for w in input_text.split("\n") if w.strip()]

    if len(lines) == 0:
        st.warning("Vui l√≤ng nh·∫≠p √≠t nh·∫•t 1 t·ª´!")
    else:
        deck = genanki.Deck(100123, "Vocabulary Deck")
        media_files = []

        for i, word in enumerate(lines, 1):
            st.write(f"üîÑ ƒêang x·ª≠ l√Ω {i}/{len(lines)}: **{word}**")

            # --- X√°c ƒë·ªãnh lo·∫°i t·ª´ & nghƒ©a ---
            pos = get_pos(word)
            eng_def = get_definition(word)
            vi_def = translate_word(eng_def or word)

            # --- L·∫•y h√¨nh ·∫£nh ---
            img_bytes = fetch_image(word)
            img_name = safe_name(word) + ".jpg"
            with open(img_name, "wb") as f:
                f.write(img_bytes)
            media_files.append(img_name)

            # --- T·∫°o √¢m thanh ---
            mp3_name = safe_name(word) + ".mp3"
            try:
                tts = gTTS(word)
                tts.save(mp3_name)
                media_files.append(mp3_name)
            except:
                mp3_name = ""

            # --- N·ªôi dung front card ---
            front = f"<img src='{img_name}'/><br><b>{word}</b> <i>({pos})</i>"
            if mp3_name:
                front += f"<br>[sound:{mp3_name}]"

            back = vi_def

            deck.add_note(genanki.Note(
                model=genanki.BASIC_MODEL,
                fields=[front, back]
            ))

            time.sleep(0.2)  # tr√°nh request qu√° nhanh

        # --- T·∫°o file .apkg ---
        package = genanki.Package(deck)
        package.media_files = media_files
        output_file = "flashcards.apkg"
        package.write_to_file(output_file)

        # --- Cho ng∆∞·ªùi d√πng t·∫£i v·ªÅ ---
        with open(output_file, "rb") as f:
            st.download_button("‚¨áÔ∏è Download .apkg", f, file_name="flashcards.apkg")

        st.success("‚úÖ Ho√†n th√†nh! T·∫£i file flashcards v√† m·ªü b·∫±ng Anki.")
